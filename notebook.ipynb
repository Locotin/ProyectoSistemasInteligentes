{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola mundo\n"
     ]
    }
   ],
   "source": [
    "print(\"hola mundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… OrganizaciÃ³n Final de Conjuntos:\n",
      "  - Train: 2394 imÃ¡genes\n",
      "  - Validation: 185 imÃ¡genes\n",
      "  - Test_patches: 1119 imÃ¡genes (Debe ser 1119)\n"
     ]
    }
   ],
   "source": [
    "# Directorios de imÃ¡genes\n",
    "train_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train\"\n",
    "val_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/validation\"\n",
    "test_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/test_patches\"\n",
    "\n",
    "# Rutas de etiquetas\n",
    "train_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train_labels.csv\"\n",
    "val_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/val_labels.csv\"\n",
    "\n",
    "# ğŸ“Œ 1ï¸âƒ£ Cargar imÃ¡genes de `train` y sus etiquetas\n",
    "df_train = pd.read_csv(train_label_path)\n",
    "df_train[\"image_name\"] = df_train[\"slide\"].astype(str) + \"_\" + df_train[\"rid\"].astype(str) + \".tif\"\n",
    "\n",
    "# ğŸ“Œ 2ï¸âƒ£ Cargar imÃ¡genes de `validation` y sus etiquetas\n",
    "val_images = [f for f in os.listdir(val_image_dir) if f.endswith(\".tif\")]\n",
    "df_val = pd.DataFrame({\"image_name\": val_images})\n",
    "df_val[[\"slide\", \"rid\"]] = df_val[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "\n",
    "# Cargar etiquetas de `val_labels.csv` (solo para validaciÃ³n)\n",
    "df_val_labels = pd.read_csv(val_label_path)\n",
    "df_val = df_val.merge(df_val_labels, on=[\"slide\", \"rid\"], how=\"left\")\n",
    "\n",
    "# ğŸ“Œ 3ï¸âƒ£ Cargar imÃ¡genes de `test_patches` (sin etiquetas)\n",
    "test_images = [f for f in os.listdir(test_image_dir) if f.endswith(\".tif\")]\n",
    "df_test = pd.DataFrame({\"image_name\": test_images})\n",
    "df_test[[\"slide\", \"rid\"]] = df_test[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "\n",
    "# ğŸ“Œ 4ï¸âƒ£ Resumen de conjuntos de datos\n",
    "print(\"\\nâœ… OrganizaciÃ³n Final de Conjuntos:\")\n",
    "print(f\"  - Train: {len(df_train)} imÃ¡genes\")\n",
    "print(f\"  - Validation: {len(df_val)} imÃ¡genes\")\n",
    "print(f\"  - Test_patches: {len(df_test)} imÃ¡genes (Debe ser 1119)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx][\"image_name\"]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image, img_name\n",
    "        else:\n",
    "            label = self.df.iloc[idx][\"y\"]\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Crear datasets y dataloaders\n",
    "train_dataset = BreastDataset(df_train, train_image_dir, transform)\n",
    "val_dataset = BreastDataset(df_val, val_image_dir, transform)\n",
    "test_dataset = BreastDataset(df_test, test_image_dir, transform, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Dispositivo en uso: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ“Œ Dispositivo en uso: {device}\")\n",
    "\n",
    "resnet34 = models.resnet34(weights=\"IMAGENET1K_V1\")\n",
    "resnet34.fc = nn.Linear(512, 1)  # Modificar la capa final para regresiÃ³n\n",
    "resnet34 = resnet34.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(resnet34.parameters(), lr=0.001) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Ã‰poca 1/10 - PÃ©rdida: 0.1460\n",
      "ğŸ“Œ Ã‰poca 2/10 - PÃ©rdida: 0.0274\n",
      "ğŸ“Œ Ã‰poca 3/10 - PÃ©rdida: 0.0196\n",
      "ğŸ“Œ Ã‰poca 4/10 - PÃ©rdida: 0.0180\n",
      "ğŸ“Œ Ã‰poca 5/10 - PÃ©rdida: 0.0200\n",
      "ğŸ“Œ Ã‰poca 6/10 - PÃ©rdida: 0.0133\n",
      "ğŸ“Œ Ã‰poca 7/10 - PÃ©rdida: 0.0119\n",
      "ğŸ“Œ Ã‰poca 8/10 - PÃ©rdida: 0.0084\n",
      "ğŸ“Œ Ã‰poca 9/10 - PÃ©rdida: 0.0072\n",
      "ğŸ“Œ Ã‰poca 10/10 - PÃ©rdida: 0.0085\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    resnet34.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet34(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()s\n",
    "    \n",
    "    print(f\"ğŸ“Œ Ã‰poca {epoch+1}/{epochs} - PÃ©rdida: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Archivo de predicciones generado: submission_test.csv\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "resnet34.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = resnet34(images).squeeze().cpu().numpy()\n",
    "        outputs = F.sigmoid(torch.tensor(outputs)).numpy()  # Convertir a [0,1]\n",
    "\n",
    "        for img_name, pred in zip(image_names, outputs):\n",
    "            slide, rid = img_name.replace(\".tif\", \"\").split(\"_\")\n",
    "            test_predictions.append([int(slide), int(rid), pred])\n",
    "\n",
    "df_test_predictions = pd.DataFrame(test_predictions, columns=[\"slide\", \"rid\", \"score\"])\n",
    "df_test_predictions.to_csv(\"submission_test.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Archivo de predicciones generado: submission_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pk(labels, predictions):\n",
    "    P, Q, T = 0, 0, 0\n",
    "    for (pred_i, true_i), (pred_j, true_j) in itertools.combinations(zip(predictions, labels), 2):\n",
    "        if (true_i < true_j and pred_i < pred_j) or (true_i > true_j and pred_i > pred_j):\n",
    "            P += 1\n",
    "        elif (true_i < true_j and pred_i > pred_j) or (true_i > true_j and pred_i < pred_j):\n",
    "            Q += 1\n",
    "        elif pred_i == pred_j:\n",
    "            T += 1\n",
    "    return (((P - Q) / (P + Q + T)) + 1) / 2 if (P + Q + T) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    EvalÃºa el modelo en el conjunto de validaciÃ³n usando MSE, MAE, RÂ² y PK.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels, all_predictions = [], []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    mse = mean_squared_error(all_labels, all_predictions)\n",
    "    mae = mean_absolute_error(all_labels, all_predictions)\n",
    "    r2 = r2_score(all_labels, all_predictions)\n",
    "    pk = calculate_pk(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"ğŸ“Œ MSE: {mse:.4f}, MAE: {mae:.4f}, RÂ²: {r2:.4f}, PK: {pk:.4f}\")\n",
    "\n",
    "    return mse, mae, r2, pk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ MSE: 0.0428, MAE: 0.1418, RÂ²: 0.5074, PK: 0.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04278333514366463,\n",
       " 0.14183138127665262,\n",
       " 0.5073858931966435,\n",
       " 0.8181243280844874)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet34, val_loader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisisvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
