{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola mundo\n"
     ]
    }
   ],
   "source": [
    "print(\"hola mundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Organización Final de Conjuntos:\n",
      "  - Train: 2394 imágenes\n",
      "  - Validation: 185 imágenes\n",
      "  - Test_patches: 1119 imágenes (Debe ser 1119)\n"
     ]
    }
   ],
   "source": [
    "# Directorios de imágenes\n",
    "train_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train\"\n",
    "val_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/validation\"\n",
    "test_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/test_patches\"\n",
    "\n",
    "# Rutas de etiquetas\n",
    "train_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train_labels.csv\"\n",
    "val_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/val_labels.csv\"\n",
    "\n",
    "# 📌 1️⃣ Cargar imágenes de `train` y sus etiquetas\n",
    "df_train = pd.read_csv(train_label_path)\n",
    "df_train[\"image_name\"] = df_train[\"slide\"].astype(str) + \"_\" + df_train[\"rid\"].astype(str) + \".tif\"\n",
    "\n",
    "# 📌 2️⃣ Cargar imágenes de `validation` y sus etiquetas\n",
    "val_images = [f for f in os.listdir(val_image_dir) if f.endswith(\".tif\")]\n",
    "df_val = pd.DataFrame({\"image_name\": val_images})\n",
    "df_val[[\"slide\", \"rid\"]] = df_val[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "\n",
    "# Cargar etiquetas de `val_labels.csv` (solo para validación)\n",
    "df_val_labels = pd.read_csv(val_label_path)\n",
    "df_val = df_val.merge(df_val_labels, on=[\"slide\", \"rid\"], how=\"left\")\n",
    "\n",
    "# 📌 3️⃣ Cargar imágenes de `test_patches` (sin etiquetas)\n",
    "test_images = [f for f in os.listdir(test_image_dir) if f.endswith(\".tif\")]\n",
    "df_test = pd.DataFrame({\"image_name\": test_images})\n",
    "df_test[[\"slide\", \"rid\"]] = df_test[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "\n",
    "# 📌 4️⃣ Resumen de conjuntos de datos\n",
    "print(\"\\n✅ Organización Final de Conjuntos:\")\n",
    "print(f\"  - Train: {len(df_train)} imágenes\")\n",
    "print(f\"  - Validation: {len(df_val)} imágenes\")\n",
    "print(f\"  - Test_patches: {len(df_test)} imágenes (Debe ser 1119)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx][\"image_name\"]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image, img_name\n",
    "        else:\n",
    "            label = self.df.iloc[idx][\"y\"]\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Crear datasets y dataloaders\n",
    "train_dataset = BreastDataset(df_train, train_image_dir, transform)\n",
    "val_dataset = BreastDataset(df_val, val_image_dir, transform)\n",
    "test_dataset = BreastDataset(df_test, test_image_dir, transform, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Dispositivo en uso: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"📌 Dispositivo en uso: {device}\")\n",
    "\n",
    "resnet34 = models.resnet34(weights=\"IMAGENET1K_V1\")\n",
    "resnet34.fc = nn.Linear(512, 1)  # Modificar la capa final para regresión\n",
    "resnet34 = resnet34.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(resnet34.parameters(), lr=0.001) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Época 1/10 - Pérdida: 0.1460\n",
      "📌 Época 2/10 - Pérdida: 0.0274\n",
      "📌 Época 3/10 - Pérdida: 0.0196\n",
      "📌 Época 4/10 - Pérdida: 0.0180\n",
      "📌 Época 5/10 - Pérdida: 0.0200\n",
      "📌 Época 6/10 - Pérdida: 0.0133\n",
      "📌 Época 7/10 - Pérdida: 0.0119\n",
      "📌 Época 8/10 - Pérdida: 0.0084\n",
      "📌 Época 9/10 - Pérdida: 0.0072\n",
      "📌 Época 10/10 - Pérdida: 0.0085\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    resnet34.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet34(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()s\n",
    "    \n",
    "    print(f\"📌 Época {epoch+1}/{epochs} - Pérdida: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo de predicciones generado: submission_test.csv\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "resnet34.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = resnet34(images).squeeze().cpu().numpy()\n",
    "        outputs = F.sigmoid(torch.tensor(outputs)).numpy()  # Convertir a [0,1]\n",
    "\n",
    "        for img_name, pred in zip(image_names, outputs):\n",
    "            slide, rid = img_name.replace(\".tif\", \"\").split(\"_\")\n",
    "            test_predictions.append([int(slide), int(rid), pred])\n",
    "\n",
    "df_test_predictions = pd.DataFrame(test_predictions, columns=[\"slide\", \"rid\", \"score\"])\n",
    "df_test_predictions.to_csv(\"submission_test.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Archivo de predicciones generado: submission_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pk(labels, predictions):\n",
    "    P, Q, T = 0, 0, 0\n",
    "    for (pred_i, true_i), (pred_j, true_j) in itertools.combinations(zip(predictions, labels), 2):\n",
    "        if (true_i < true_j and pred_i < pred_j) or (true_i > true_j and pred_i > pred_j):\n",
    "            P += 1\n",
    "        elif (true_i < true_j and pred_i > pred_j) or (true_i > true_j and pred_i < pred_j):\n",
    "            Q += 1\n",
    "        elif pred_i == pred_j:\n",
    "            T += 1\n",
    "    return (((P - Q) / (P + Q + T)) + 1) / 2 if (P + Q + T) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo en el conjunto de validación usando MSE, MAE, R² y PK.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels, all_predictions = [], []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    mse = mean_squared_error(all_labels, all_predictions)\n",
    "    mae = mean_absolute_error(all_labels, all_predictions)\n",
    "    r2 = r2_score(all_labels, all_predictions)\n",
    "    pk = calculate_pk(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"📌 MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}, PK: {pk:.4f}\")\n",
    "\n",
    "    return mse, mae, r2, pk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 MSE: 0.0428, MAE: 0.1418, R²: 0.5074, PK: 0.8181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04278333514366463,\n",
       " 0.14183138127665262,\n",
       " 0.5073858931966435,\n",
       " 0.8181243280844874)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(resnet34, val_loader, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisisvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
