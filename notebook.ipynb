{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Train: 2394 imÃ¡genes\n",
      "ðŸ“Œ Test: 185 imÃ¡genes\n",
      "ðŸ“Œ Validation: 185 imÃ¡genes\n"
     ]
    }
   ],
   "source": [
    "# Directorios de imÃ¡genes\n",
    "train_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train\"\n",
    "val_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/validation\"\n",
    "test_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/test_patches\"\n",
    "\n",
    "# Rutas de etiquetas\n",
    "train_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train_labels.csv\"\n",
    "test_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/val_labels.csv\"\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv(train_label_path)\n",
    "df_test = pd.read_csv(test_label_path)\n",
    "\n",
    "# Agregar nombres de archivos a los DataFrames\n",
    "df_train[\"image_name\"] = df_train[\"slide\"].astype(str) + \"_\" + df_train[\"rid\"].astype(str) + \".tif\"\n",
    "df_test[\"image_name\"] = df_test[\"slide\"].astype(str) + \"_\" + df_test[\"rid\"].astype(str) + \".tif\"\n",
    "\n",
    "# Cargar imÃ¡genes de validaciÃ³n\n",
    "val_images = [f for f in os.listdir(val_image_dir) if f.endswith(\".tif\")]\n",
    "df_val = pd.DataFrame({\"image_name\": val_images})\n",
    "\n",
    "# Verificar los tamaÃ±os de los datasets\n",
    "print(f\"ðŸ“Œ Train: {len(df_train)} imÃ¡genes\")\n",
    "print(f\"ðŸ“Œ Test: {len(df_test)} imÃ¡genes\")\n",
    "print(f\"ðŸ“Œ Validation: {len(df_val)} imÃ¡genes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels_df, transform=None, labeled=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.labels_df.iloc[idx][\"image_name\"]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.labeled:\n",
    "            label = torch.tensor(self.labels_df.iloc[idx][\"y\"], dtype=torch.float32)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, img_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ DataLoader de entrenamiento creado con 2394 imÃ¡genes\n",
      "ðŸ“Œ DataLoader de validaciÃ³n creado con 185 imÃ¡genes\n",
      "ðŸ“Œ DataLoader de test creado con 185 imÃ¡genes\n"
     ]
    }
   ],
   "source": [
    "# Definir transformaciones para las imÃ¡genes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = CustomDataset(train_image_dir, df_train, transform=transform, labeled=True)\n",
    "validation_dataset = CustomDataset(val_image_dir, df_val, transform=transform, labeled=False)\n",
    "test_dataset = CustomDataset(test_image_dir, df_test, transform=transform, labeled=False)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"ðŸ“Œ DataLoader de entrenamiento creado con {len(train_dataset)} imÃ¡genes\")\n",
    "print(f\"ðŸ“Œ DataLoader de validaciÃ³n creado con {len(validation_dataset)} imÃ¡genes\")\n",
    "print(f\"ðŸ“Œ DataLoader de test creado con {len(test_dataset)} imÃ¡genes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Dispositivo en uso: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸ“Œ Dispositivo en uso: {device}\")\n",
    "\n",
    "# Cargar modelo preentrenado\n",
    "resnet34 = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "resnet34.fc = nn.Linear(resnet34.fc.in_features, 1)  # Modificar la capa final para regresiÃ³n\n",
    "resnet34 = resnet34.to(device)\n",
    "\n",
    "# Definir funciÃ³n de pÃ©rdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(resnet34.parameters(), lr=0.0001)  # Definir learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Ã‰poca 1/10 - PÃ©rdida: 0.1386\n",
      "ðŸ“Œ Ã‰poca 2/10 - PÃ©rdida: 0.0208\n",
      "ðŸ“Œ Ã‰poca 3/10 - PÃ©rdida: 0.0134\n",
      "ðŸ“Œ Ã‰poca 4/10 - PÃ©rdida: 0.0104\n",
      "ðŸ“Œ Ã‰poca 5/10 - PÃ©rdida: 0.0084\n",
      "ðŸ“Œ Ã‰poca 6/10 - PÃ©rdida: 0.0077\n",
      "ðŸ“Œ Ã‰poca 7/10 - PÃ©rdida: 0.0058\n",
      "ðŸ“Œ Ã‰poca 8/10 - PÃ©rdida: 0.0053\n",
      "ðŸ“Œ Ã‰poca 9/10 - PÃ©rdida: 0.0044\n",
      "ðŸ“Œ Ã‰poca 10/10 - PÃ©rdida: 0.0047\n",
      "âœ… Entrenamiento finalizado\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet34.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet34(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"ðŸ“Œ Ã‰poca {epoch+1}/{num_epochs} - PÃ©rdida: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"âœ… Entrenamiento finalizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… GeneraciÃ³n de predicciones completada.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Llamar a la evaluaciÃ³n solo con conjuntos etiquetados\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet34\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 24\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, labeled)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labeled:\n\u001b[1;32m     23\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 24\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     images, image_names \u001b[38;5;241m=\u001b[39m batch\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "def calculate_pk(labels, predictions):\n",
    "    P, Q, T = 0, 0, 0\n",
    "    for (pred_i, true_i), (pred_j, true_j) in itertools.combinations(zip(predictions, labels), 2):\n",
    "        if (true_i < true_j and pred_i < pred_j) or (true_i > true_j and pred_i > pred_j):\n",
    "            P += 1\n",
    "        elif (true_i < true_j and pred_i > pred_j) or (true_i > true_j and pred_i < pred_j):\n",
    "            Q += 1\n",
    "        elif pred_i == pred_j:\n",
    "            T += 1\n",
    "    return (((P - Q) / (P + Q + T)) + 1) / 2 if (P + Q + T) != 0 else 0\n",
    "\n",
    "def evaluate_model(model, data_loader, labeled=True):\n",
    "    \"\"\"\n",
    "    EvalÃºa el modelo en el conjunto de datos usando MSE, MAE, RÂ² y PK.\n",
    "    Si `labeled` es False, solo genera predicciones sin comparar con etiquetas.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_labels, all_predictions = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if labeled:\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            else:\n",
    "                images, image_names = batch\n",
    "                images = images.to(device)\n",
    "            \n",
    "            outputs = model(images).squeeze().cpu().numpy()\n",
    "            \n",
    "            if labeled:\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(outputs)\n",
    "\n",
    "    if labeled:\n",
    "        mse = mean_squared_error(all_labels, all_predictions)\n",
    "        mae = mean_absolute_error(all_labels, all_predictions)\n",
    "        r2 = r2_score(all_labels, all_predictions)\n",
    "        pk = calculate_pk(all_labels, all_predictions)\n",
    "        print(f\"ðŸ“Œ MSE: {mse:.4f}, MAE: {mae:.4f}, RÂ²: {r2:.4f}, PK: {pk:.4f}\")\n",
    "    else:\n",
    "        print(\"âœ… GeneraciÃ³n de predicciones completada.\")\n",
    "\n",
    "# Llamar a la evaluaciÃ³n solo con conjuntos etiquetados\n",
    "evaluate_model(resnet34, validation_loader, labeled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Archivo de predicciones generado correctamente: submission_test.csv\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "resnet34.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = resnet34(images).squeeze().cpu().numpy()\n",
    "\n",
    "        # Asegurar que los valores de salida estÃ©n en el rango [0,1]\n",
    "        outputs = np.clip(outputs, 0, 1)\n",
    "\n",
    "        for img_name, pred in zip(image_names, outputs):\n",
    "            slide, rid = img_name.replace(\".tif\", \"\").split(\"_\")\n",
    "            test_predictions.append([int(slide), int(rid), pred])\n",
    "\n",
    "# Crear el DataFrame con el formato requerido\n",
    "df_test_predictions = pd.DataFrame(test_predictions, columns=[\"slide\", \"rid\", \"score\"])\n",
    "\n",
    "# Guardar en CSV\n",
    "submission_test_path = \"submission_test.csv\"\n",
    "df_test_predictions.to_csv(submission_test_path, index=False)\n",
    "\n",
    "print(f\"âœ… Archivo de predicciones generado correctamente: {submission_test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisisvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
