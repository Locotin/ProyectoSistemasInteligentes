{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Organizaci√≥n Final de Conjuntos:\n",
      "  - Train: 2394 im√°genes\n",
      "  - Validation: 185 im√°genes\n",
      "  - Test_patches: 1119 im√°genes (Debe ser 1119)\n"
     ]
    }
   ],
   "source": [
    "# Directorios de im√°genes\n",
    "train_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train\"\n",
    "val_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/validation\"\n",
    "test_image_dir = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/test_patches\"\n",
    "\n",
    "# Rutas de etiquetas\n",
    "train_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Training_Validation/breastpathq/datasets/train_labels.csv\"\n",
    "val_label_path = \"/home/angel/Documentos/ProyectoSistemasInteligentes/datasets/SPIE_BreastPathQ2019_Testing/breastpathq-test/val_labels.csv\"\n",
    "\n",
    "# Cargar datos\n",
    "print(\"\\n‚úÖ Organizaci√≥n Final de Conjuntos:\")\n",
    "df_train = pd.read_csv(train_label_path)\n",
    "df_train[\"image_name\"] = df_train[\"slide\"].astype(str) + \"_\" + df_train[\"rid\"].astype(str) + \".tif\"\n",
    "print(f\"  - Train: {len(df_train)} im√°genes\")\n",
    "\n",
    "val_images = [f for f in os.listdir(val_image_dir) if f.endswith(\".tif\")]\n",
    "df_val = pd.DataFrame({\"image_name\": val_images})\n",
    "df_val[[\"slide\", \"rid\"]] = df_val[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "df_val_labels = pd.read_csv(val_label_path)\n",
    "df_val = df_val.merge(df_val_labels, on=[\"slide\", \"rid\"], how=\"left\")\n",
    "print(f\"  - Validation: {len(df_val)} im√°genes\")\n",
    "\n",
    "test_images = [f for f in os.listdir(test_image_dir) if f.endswith(\".tif\")]\n",
    "df_test = pd.DataFrame({\"image_name\": test_images})\n",
    "df_test[[\"slide\", \"rid\"]] = df_test[\"image_name\"].str.extract(r'(\\d+)_(\\d+).tif').astype(int)\n",
    "print(f\"  - Test_patches: {len(df_test)} im√°genes (Debe ser 1119)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y DataLoader\n",
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx][\"image_name\"]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.is_test:\n",
    "            return image, img_name\n",
    "        else:\n",
    "            label = self.df.iloc[idx][\"y\"]\n",
    "            return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = BreastDataset(df_train, train_image_dir, transform)\n",
    "val_dataset = BreastDataset(df_val, val_image_dir, transform)\n",
    "test_dataset = BreastDataset(df_test, test_image_dir, transform, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üìå Dispositivo en uso: {device}\")\n",
    "\n",
    "from torchvision.models import efficientnet_v2_m\n",
    "\n",
    "efficientnet = efficientnet_v2_m(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = efficientnet.classifier[1].in_features\n",
    "efficientnet.classifier[1] = nn.Linear(num_ftrs, 1)\n",
    "efficientnet = efficientnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(efficientnet.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisisvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
